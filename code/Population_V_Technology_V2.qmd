---
title: "Population size Versus the frequency of Oakhurst and Wilton technology"
author: "Alex Gregory"
format: pdf
editor: visual
---

```{r}
library(chronup)
library(rstanarm)
library(bayesrules)
library(bayesplot)
library(tidyverse)
library(tidybayes)
library(broom.mixed)


library(geodata)

library(nimble)
library(ggplot2)
library(forcats)
library(cowplot)
library(ggpubr)
library(tidyr)
library(dplyr)
library(chronup)
library(abind)
library(clam)
library(pastclim)
library(tibble)
library(c14bazAAR)
library(MCMCvis)
library(chronup)
library(rcarbon)
# Map
library(tmap)
library(ggmap)
library(raster)
library(broom)
library(cowplot)
# Parallel
library(foreach)
library(doParallel)
# Bayes
library(bayesrules)
library(bayesplot)
library(tidyverse)
library(tidybayes)
library(broom.mixed)
library(rstanarm)
```

```{r}
plot_count_ensemble.mod <- function (count_ensemble, times, use_ggplot2 = FALSE, axis_x_res = 100, 
    axis_y_res = 1) 
{
    nevents <- sum(count_ensemble[, 1])
    event_count_freqs <- t(apply(count_ensemble, 1, chronup::tabulate_freqs, 
        nevents = nevents))
    max_count <- chronup::find_max_count(event_count_freqs)
    event_count_freqs_na <- event_count_freqs
    event_count_freqs_na[which(event_count_freqs_na == 0)] <- NA
    event_count_freqs_na <- event_count_freqs_na[, 2:max_count]
    if (use_ggplot2) {
        ggplot2_installed <- requireNamespace("ggplot2", quietly = TRUE)
        if (ggplot2_installed) {
            ncols <- dim(event_count_freqs_na)[2]
            event_count_freqs_df <- as.data.frame(cbind(times, 
                event_count_freqs_na))
            colnames <- c("x", as.character(1:ncols))
            names(event_count_freqs_df) <- colnames
            event_count_freqs_df_long <- tidyr::pivot_longer(event_count_freqs_df, 
                cols = 2:ncols, names_to = "y", values_to = "frequency")
            p <- ggplot2::ggplot(data = event_count_freqs_df_long, 
                mapping = ggplot2::aes(x = .data$x, y = .data$y)) + 
                ggplot2::geom_raster(mapping = ggplot2::aes(fill = frequency)) + 
                ggplot2::scale_fill_viridis_c(option = "B", na.value = grDevices::rgb(0, 
                  0, 0, 0), begin = 0.15, alpha = 0.9, trans = "log") + 
                ggplot2::labs(x = "Time", y = "Count") + # remove legend+
            scale_x_reverse() +
              theme_bw() + theme(panel.border = element_blank(),
                                 #panel.grid.major = element_blank(),
                                 panel.grid.minor = element_blank(),
                                 legend.position = "none",
                                 text = element_text(size = 20))# reverse x-axis
            print(p)
            return(p)
        }
        else {
            stop("ggplot2 not installed.")
        }
    }
    else {
        image(x = 1:dim(event_count_freqs_na)[1], y = 1:dim(event_count_freqs_na)[2], 
            z = event_count_freqs_na, useRaster = T, col = grDevices::hcl.colors(n = 10, 
                palette = "viridis", alpha = 0.9), axes = FALSE, 
            xlab = "Time", ylab = "Count")
        axis_y_at <- seq(1, dim(event_count_freqs_na)[2], axis_y_res)
        axis_x_at <- seq(1, dim(event_count_freqs_na)[1], axis_x_res)
        axis(1, at = axis_x_at, labels = times[axis_x_at])
        axis(2, at = axis_y_at)
    }
    return()
}
```

```{r}
dir <- here::here()
```

```{r}
# import data
SARD.df <- read.csv(paste0(dir,"/data/SARD_Mar2021_14C.csv"))

# convert into a format suitable for radiocarbon calibration
SARD.df |>
  rename(site = X.Site,
         c14age = Date,
         c14std = Uncertainty,
         culture = Archaeological.Sub.chronology,
         lat = DecdegS,
         lon = DecdegE) |>
  mutate_at(c("c14age", "c14std"), as.numeric) -> SARD

##########################

# filter data by date
sard.map <- SARD.df |>
  mutate(Date = as.numeric(Date)) |>
  filter(Date < 12000 & Date > 4000)

# Summarize the number of chronology types in the filtered data
sard.map |>
  group_by(Archaeological.Sub.chronology) |>
  summarize(n())

# Create an uncalibrated list of radiocarbon dates and export to a CSV
sard.map |> dplyr::select(X.Site, DecdegS, DecdegE, 
                          Country, Biome,
                          Date, Uncertainty, 
                          Archaeological.Sub.chronology) |>
  rename(site = X.Site, lat = DecdegS, lon = DecdegE,
         `Technological Complex` = Archaeological.Sub.chronology)-> SARD.out
write.csv(SARD.out, paste0(dir,"/data/Radiocarbon_data_uncalib.csv"), sep = ",")


```

# Export all relevant databases for OxCal

```{r}
# Select all Oakhurst and Wilton
SARD |> 
  filter(c14age < max(SARD$c14age[which(culture == "Oakhurst")]) &
           c14age > min(SARD$c14age[which(culture == "Wilton")])) |>
  
  filter(Species != "Homo sapiens") -> SARD_Oak_Wil

# Select and trim Oakhurst and Wilton dates
SARD_Oak_Wil |>
  filter(culture == "Oakhurst") |>
  filter(c14age > quantile(c14age, 0.05) &
           c14age < quantile(c14age, 0.95)) -> SARD_Oak_trimmed

SARD_Oak_Wil |>
  filter(culture == "Wilton") |>
  filter(c14age > quantile(c14age, 0.05) &
           c14age < quantile(c14age, 0.95)) -> SARD_Wil_trimmed



# Filter and organize for expected OxCal input
# Also exclude dates associated with the transition layer
SARD_Oak_trimmed |>
    dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  filter(c14age > max(SARD_Wil_trimmed$c14age)) |>
  arrange(desc(c14age)) |>
  mutate(Samp = c(rep(seq(1,3,1), floor(n()/3)), seq(1,n()%%3,1))) -> SARD_Oak_Temp
write.csv(SARD_Oak_Temp, paste0(dir,"/data/SARD_Oak_Trimmed.csv"))

SARD_Wil_trimmed |>
    dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  filter(c14age < min(SARD_Oak_trimmed$c14age)) |>
  arrange(desc(c14age)) |>
  mutate(Samp = c(rep(seq(1,3,1), floor(n()/3)), seq(1,n()%%3,1))) -> SARD_Wil_Temp
write.csv(SARD_Wil_Temp, paste0(dir,"/data/SARD_Wil_Trimmed.csv"))

# Create output for a transition layer in OxCal
SARD_Oak_trimmed |>
  dplyr::filter(SARD_Oak_trimmed$c14age <= max(SARD_Wil_trimmed$c14age)) -> Oak_Tran

SARD_Wil_trimmed |>
  dplyr::filter(SARD_Wil_trimmed$c14age >= 
                  min(SARD_Oak_trimmed$c14age)) -> Wil_Tran

rbind(Oak_Tran, Wil_Tran) |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) |>
  dplyr::distinct(Lab.ID, .keep_all = TRUE) -> Oak_Wil_Tran
write.csv(Oak_Wil_Tran, paste0(dir,"/data/Oak_Wil_Trimmed_Transition.csv"))




###################################################################################
# Select all data based on Oakhurst and Wilton time periods
SARD |> 
  filter(c14age < max(SARD_Oak_trimmed$c14age) &
                 c14age > min(SARD_Wil_trimmed$c14age)) -> SARD_All

SARD_All |>
  filter(c14age < max(SARD_Oak_trimmed$c14age) &
                 c14age > min(SARD_Oak_trimmed$c14age)) -> SARD_All_Oak

SARD_All |>
  filter(c14age < max(SARD_Wil_trimmed$c14age) &
                 c14age > min(SARD_Wil_trimmed$c14age)) -> SARD_All_Wil


# Filter and organize for expected OxCal input
# Also exclude dates associated with the transition layer
SARD_All_Oak |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  filter(c14age > max(SARD_All_Wil$c14age)) |>
  arrange(desc(c14age)) |>
  mutate(Samp = c(rep(seq(1,3,1), floor(n()/3)))) -> SARD_Oak_Temp
write.csv(SARD_Oak_Temp, paste0(dir,"/data/SARD_All_Oak_Trimmed.csv"))

SARD_All_Wil |>
    dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  filter(c14age < min(SARD_All_Oak$c14age)) |>
  arrange(desc(c14age)) |>
  mutate(Samp = c(rep(seq(1,3,1), floor(n()/3)))) -> SARD_Wil_Temp
write.csv(SARD_Wil_Temp, paste0(dir,"/data/SARD_All_Wil_Trimmed.csv"))

# Create output for a transition layer in OxCal
SARD_All_Oak |>
  dplyr::filter(SARD_All_Oak$c14age <= max(SARD_All_Wil$c14age)) -> Oak_Tran

SARD_All_Wil |>
  dplyr::filter(SARD_All_Wil$c14age >= min(SARD_All_Oak$c14age)) -> Wil_Tran

rbind(Oak_Tran, Wil_Tran) |>
    dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) |>
  dplyr::distinct(Lab.ID, .keep_all = TRUE) -> Oak_Wil_Tran
write.csv(Oak_Wil_Tran, paste0(dir,"/data/Oak_Wil_All_Transition.csv"))
```

## Winter Rainfall Zone

```{r}
# All dates within Oakhurst range
SARD_All_Oak |> 
  filter(RFZ == "W") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Oak_RFZ
write.csv(SARD_All_Oak_RFZ, paste0(dir,"/data/SARD_All_Oak_WRZ.csv"))

# Only sites associated with Oakhurst
SARD_Oak_trimmed |> 
  filter(RFZ == "W") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Oak_RFZ
write.csv(SARD_Oak_RFZ, paste0(dir,"/data/SARD_Oak_WRZ.csv"))


# All dates within Wilton range
SARD_All_Wil |> 
  filter(RFZ == "W") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Wil_RFZ
write.csv(SARD_All_Wil_RFZ, paste0(dir,"/data/SARD_All_Wil_WRZ.csv"))

# Only sites associated with Wilton
SARD_Wil_trimmed |> 
  filter(RFZ == "W") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Wil_RFZ
write.csv(SARD_Wil_RFZ, paste0(dir,"/data/SARD_Wil_WRZ.csv"))
```

## Summer Rainfall Zone

```{r}
# All dates within Oakhurst range
SARD_All_Oak |> 
  filter(RFZ == "S") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Oak_RFZ
write.csv(SARD_All_Oak_RFZ, paste0(dir,"/data/SARD_All_Oak_SRZ.csv"))

# Only sites associated with Oakhurst
SARD_Oak_trimmed |> 
  filter(RFZ == "S") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Oak_RFZ
write.csv(SARD_Oak_RFZ, paste0(dir,"/data/SARD_Oak_SRZ.csv"))


# All dates within Wilton range
SARD_All_Wil |> 
  filter(RFZ == "S") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Wil_RFZ
write.csv(SARD_All_Wil_RFZ, paste0(dir,"/data/SARD_All_Wil_SRZ.csv"))

# Only sites associated with Wilton
SARD_Wil_trimmed |> 
  filter(RFZ == "S") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Wil_RFZ
write.csv(SARD_Wil_RFZ, paste0(dir,"/data/SARD_Wil_SRZ.csv"))
```

## Year-round Rainfall Zone

```{r}
# All dates within Oakhurst range
SARD_All_Oak |> 
  filter(RFZ == "Y") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Oak_RFZ
write.csv(SARD_All_Oak_RFZ, paste0(dir,"/data/SARD_All_Oak_YRZ.csv"))

# Only sites associated with Oakhurst
SARD_Oak_trimmed |> 
  filter(RFZ == "Y") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Oak_RFZ
write.csv(SARD_Oak_RFZ, paste0(dir,"/data/SARD_Oak_YRZ.csv"))


# All dates within Wilton range
SARD_All_Wil |> 
  filter(RFZ == "Y") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Wil_RFZ
write.csv(SARD_All_Wil_RFZ, paste0(dir,"/data/SARD_All_Wil_YRZ.csv"))

# Only sites associated with Wilton
SARD_Wil_trimmed |> 
  filter(RFZ == "Y") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Wil_RFZ
write.csv(SARD_Wil_RFZ, paste0(dir,"/data/SARD_Wil_YRZ.csv"))
```

### Site Selection Based on Oakhurst and Wilton Technology

```{r}
#| include: false

#############################################
# This code is used for filtering sites based on amount and timing of radiocarbon data. I used this code to explore which sites are worth a closer exmaination

SARD |> group_by(site, culture) |> filter(culture == "Oakhurst" | culture == "Wilton") |> 
  dplyr::distinct(site, culture) |>
  mutate(cult = ifelse(culture == "Oakhurst", 1, 2)) |>
  group_by(site) |>
  summarize(s = sum(cult)) |>
  filter(s == 3) -> Sites_with_both

SARD |>
  dplyr::filter(site %in% 
                  c("Apollo 11 cave",
                    "Blydefontein",
                    "Boomplaas",
                    "Buffelskloof",
                    #"Byneskranskop 1",
                    "Elands Bay Cave",
                    "Grassridge",
                    "Havens Cave",
                    "Jubilee Shelter",
                    #"Kangkara Cave",
                    #"Matjies River",
                    "Melkhoutboom",
                    "Nelson Bay Cave",
                    "Oakhurst",
                    "Rose Cottage Cave",
                    "Sehonghong",
                    "Sophiso",
                    "Tloutle",
                    "Wilton Large Rock Shelter")) |>
  filter(c14age < max(SARD_Oak_trimmed$c14age) &
                 c14age > min(SARD_Wil_trimmed$c14age)) |>
  group_by(site, culture) |>
  summarize(c14Count = n()) -> tu


library(rnaturalearth)
library(sf)
south_africa <- ne_countries(scale = "medium", 
                             country = "South Africa", 
                             returnclass = "sf")

SARD |>
  filter(site %in% c("Elands Bay Cave", "Nelson Bay Cave",
                     "Boomplaas", "Rose Cottage Cave", "Sehonghong")) |>
  distinct(lat, lon, site) |>
  ggplot()+
  geom_sf(data = south_africa) +
  geom_point(aes(x = lon, y = lat, color = site))
```

```{r compre_Boomplaas}
BPA <- SARD |>
  filter(site == "Nelson Bay Cave") |>
  dplyr::select(site, culture, c14age, c14std, Lab.ID)
BPA_cal <- rcarbon::calibrate(BPA$c14age, BPA$c14std,
                               calCurves = "intcal20", ids = BPA$Lab.ID)

#bins <- binPrep(BPA$site, ages = caldates, h = 100)

randates <- sampleDates(BPA_cal, nsim = 1000, verbose = F)


SARD.ckde <- ckde(randates, timeRange = c(17000, 2000), bw = 200)

plot(SARD.ckde, type = "multiline")

plot(spd(BPA_cal, bins, timeRange = c(17000,2000)), add = F)
####################
NBC <- tibble(
  Strat = c("IC", "BSC", "RA",
            
            "RB", "J", "BSBJ", "CS", "GSL"),
  Strat_Date = factor(c("6.8-3.8 ka", "7.1-6.1 ka", "7.9-6.7 ka",
                 
                 "9.8-8.1 ka", "11.3-9.1 ka", "11.9-10.5 ka",
                "12.2-11.4 ka", "16.7-11.7 ka")),
  Strat_Median = factor(c((6.8+3.8)/2, (7.1+6.1)/2,(7.9+6.7)/2,
                        
                        (9.8+8.1)/2,(11.3+9.1)/2,(11.9+10.5)/2,
                        (16.7+11.7)/2, (12.2+11.4)/2)),
  
  Buckets = c(215, 415, 650,
              
              1204, 454, 818, 464, 301),
  
  Quartz = c(12.76,12.52, 11.86,
             
             2.77, 1.51, 1.76, 4.94, 4.36),
  Quartzite = c(76.68, 83.07, 87.52,
                
                96.47, 98.08, 98.12, 94.05, 86.33),
  Silcrete = c(2.18, 0.08, 0.07,
               
               0.06, 0, 0.02, 0.04, 3.47),
  Cahalcedony = c(8.27, 4.27, 0.49,
                  
                  0.56, 0.31, 0.1, 0.82, 5.84),
  
  Lithic_Bucket = c(6373/215, 14956/415, 4526/650,
                    
                    7137/1204, 4227/454, 6072/818, 2572/464, 2367/301),
  
  OES = c(3, 9, 10,
          
          4, 7, 6, 72, 2), 
  OES_finsished = c(2, 1, 0,
                    
                    1, 0, 0, 53, 0),
  
  Ochre = c(86, 183, 50,
            
            49, 58, 39, 65, 69),
  
  Formal_Flake = c(157/5921, 85/14156, 21/4288,
                   
                   27/6682, 10/4053, 7/5752, 1/2465, 2/2285),
  
  Bone_Flake = c(12/157, 14/85, 20/21,
                 24/27, 7/10, 34/7, 40/1, 6/2),
  BoneGorges_Bone = c(0/12, 0/14, 6/20,
                  4/24, 3/7, 22/34, 25/40, 1/6)
)


############# RAW MATERIAL ####################
NBC |>
  mutate(Strat_Median = fct_rev(Strat_Median)) |>
  
  pivot_longer(cols = c("Quartz":"BoneGorges_Bone")) |>
  filter(name %in%c("Quartz", "Quartzite", "Silcrete")) |>
  ggplot()+
  geom_bar(aes(x = Strat_Median, y = value), stat = "identity")+
  facet_wrap(~name)+
  theme(axis.text.x = element_text(face = "bold", color = "red",
                                   size = 8, angle = 90, vjust = -0.025))+
  theme_classic(base_size = 18)+
  
  ylab("Percent")+xlab("Ka cal. BP")

############ BONE ##########################
NBC |>
  mutate(Strat_Median = fct_rev(Strat_Median)) |>
  
  pivot_longer(cols = c("Quartz":"BoneGorges_Bone")) |>
  filter(name %in%c("Bone_Flake")) |>
  ggplot()+
  geom_bar(aes(x = Strat_Median, y = value), stat = "identity")+
  facet_wrap(~name)+
  theme(axis.text.x = element_text(face = "bold", color = "red",
                                   size = 8, angle = 90, vjust = -0.025))+
  theme_classic(base_size = 18)+
  
  ylab("Bone-to-Flaked Tools")+xlab("Ka cal. BP")

NBC |>
  mutate(Strat_Median = fct_rev(Strat_Median)) |>
  
  pivot_longer(cols = c("Quartz":"BoneGorges_Bone")) |>
  filter(name %in%c("BoneGorges_Bone")) |>
  ggplot()+
  geom_bar(aes(x = Strat_Median, y = value), stat = "identity")+
  facet_wrap(~name)+
  theme(axis.text.x = element_text(face = "bold", color = "red",
                                   size = 8, angle = 90, vjust = -0.025))+
  theme_classic(base_size = 18)+
  
  ylab("Bone Gorge-to-Bone Tools")+xlab("Ka cal. BP")

################## FORMAL ######################

NBC |>
  mutate(Strat_Median = fct_rev(Strat_Median)) |>
  
  pivot_longer(cols = c("Quartz":"BoneGorges_Bone")) |>
  filter(name %in%c("Formal_Flake")) |>
  ggplot()+
  geom_bar(aes(x = Strat_Median, y = value), stat = "identity")+
  facet_wrap(~name)+
  theme(axis.text.x = element_text(face = "bold", color = "red",
                                   size = 8, angle = 90, vjust = -0.025))+
  theme_classic(base_size = 18)+
  
  ylab("Formal Tool-to-Flake")+xlab("Ka cal. BP")

################## OES #####################
NBC |>
  mutate(Strat_Median = fct_rev(Strat_Median)) |>
  
  mutate(OES_OESFin = OES/OES_finsished) |>
  pivot_longer(cols = c("Quartz":"OES_OESFin")) |>
  filter(name %in%c("OES_OESFin")) |>
  ggplot()+
  geom_bar(aes(x = Strat_Median, y = value), stat = "identity")+
  facet_wrap(~name)+
  theme(axis.text.x = element_text(face = "bold", color = "red",
                                   size = 8, angle = 90, vjust = -0.025))+
  theme_classic(base_size = 18)+
  
  ylab("Unfinished-to-Finished OES")+xlab("Ka cal. BP")

################## OCHRE #####################

NBC |>
  mutate(Strat_Median = fct_rev(Strat_Median)) |>
  
  mutate(Ochre_Buck = Ochre/Buckets) |>
  pivot_longer(cols = c("Quartz":"Ochre_Buck")) |>
  filter(name %in%c("Ochre_Buck")) |>
  ggplot()+
  geom_bar(aes(x = Strat_Median, y = value), stat = "identity")+
  facet_wrap(~name)+
  theme(axis.text.x = element_text(face = "bold", color = "red",
                                   size = 8, angle = 90, vjust = -0.025))+
  theme_classic(base_size = 18)+
  
  ylab("Ochre Density")+xlab("Ka cal. BP")

################ LITHICS ######################
NBC |>
  mutate(Strat_Median = fct_rev(Strat_Median)) |>
  
  mutate(Ochre_Buck = Ochre/Buckets) |>
  pivot_longer(cols = c("Quartz":"Ochre_Buck")) |>
  filter(name %in%c("Lithic_Bucket")) |>
  ggplot()+
  geom_bar(aes(x = Strat_Median, y = value), stat = "identity")+
  facet_wrap(~name)+
  theme(axis.text.x = element_text(face = "bold", color = "red",
                                   size = 8, angle = 90, vjust = -0.025))+
  theme_classic(base_size = 18)+
  
  ylab("Lithic Density")+xlab("Ka cal. BP")
```

```{r compare_ElandsBayCave}
#| include: false

###########################################
# This is an extension from the above code chunk which compiles tabulated data on Elands Bay Cave to examine trends through time

# Take lithic data from Orton, 2006 and non-lithic data from Jerardino, 2021
El <- tibble(
  Artifact = c("Beads", "Ochre", "Processing Tools", "Fish Gorges", "VOlume"),
  
  `10` = c(6.8, 2.3, 0.9, 6.5, 3.1),
  `11-13` = c(19.2, 4.1, 1.8, 336.3, 2.4),
  `14-15` = c(60.6, 16.3, 2.5, 1.5, 2.7),
  `16` = c(68, 25, 2.8, 0, 1),
  `17-19` = c(37.8, 4.3, 1.4, 0, 2.3))

El_dates <- tibble(
  STRAT = c(10, "11-13", "14-15", 16, "17-19"),
  Dtae = c("8.7-9.8", "9.8-10.9", "10.6-12.6", "11.6-13.2", "14.6-15.9")
)

#### Scrapppppz
SARD.hol <- SARD |> filter(c14age < 16450 & c14age > 2220 &
                           site == "Elands Bay Cave") 
caldates <- rcarbon::calibrate(SARD.hol$c14age, SARD.hol$c14std,
                               calCurves = "intcal20", ids = SARD.hol$Lab.ID)

bins <- binPrep(SARD.hol$site, ages = caldates, h = 100)

randates <- sampleDates(caldates, bins = bins, nsim = 1000, verbose = F)


SARD.ckde <- ckde(randates, timeRange = c(17000, 2000), bw = 200)

plot(SARD.ckde, type = "multiline")

plot(spd(caldates, bins, timeRange = c(17000,2000)), add = F)
```

```{r}
El |>
  pivot_longer(cols = c('10':'17-19')) |>
  ggplot()+
  geom_bar(aes(y = name, x = log(value)), stat = 'identity')+
  facet_grid(~Artifact)
```

# Figure 2: Example Summed Distribution

```{r}
# filter and organize data to be calibrated by c14bazaar
df.sard <- as.c14_date_list(SARD) |>
  rename(labnr = Lab.ID) |>
  filter(is.na(c14age)==FALSE &
          is.na(c14std)==FALSE) |>
  filter(site == "Boomplaas") |>
  c14bazAAR::remove_duplicates()
dens1.cal <- rcarbon::calibrate(x=df.sard$c14age, errors=df.sard$c14std)

# plot individual dates for elands bay cave
multiplot(subset(dens1.cal, BP<15000&BP>2000, p=0.01), label=F)

# plot cumulative sum distribution
DK.spd = spd(dens1.cal,timeRange=c(15000,2000))
plot(DK.spd)



```

# Figure 3: Example Datatset for Process and REC

```{r}
samp.int <- 2000 # define time interval we will examine (in years)
samp.times <- 10000:8001 # define the boundary for the interval
samp.beta <- 0.04 # define the beta coeficient to define the probability distribution
samp.process <- sqrt(samp.beta*(1:samp.int)) # create probability distribution
samp.nevents <- 500 # number of example dates with the 2,000 year interval

samp.nsamples <- 20000 # number of samples to take
samp.sim_sequences <- simulate_event_counts(process = samp.process,
                            times = samp.times,
                            nevents = samp.nevents,
                            nsamples = samp.nsamples,
                            parallel = T)


plot(y = samp.process,
    x = samp.times,
    type = "l",
    xlim = c(samp.times[1], samp.times[length(samp.times)]),
    xlab = "Time",
    ylab = "Process Level")



plot(y = samp.sim_sequences$counts$Count,
    x = samp.sim_sequences$counts$Timestamps,
    type = "h",
    xlim = c(samp.times[1], samp.times[length(samp.times)]),
    xlab = "Time",
    ylab = "Count")
grid()


plot_count_ensemble.mod(count_ensemble = samp.sim_sequences$count_ensemble,
                    times = (samp.sim_sequences$new_times),
                    use_ggplot2 = T)
```

# Figure 4: RECE for 12-3 ka cal. BP (radiocarbon)

```{r}
# This code creates an ensemble from 12-3 thousand years ago
nintervals <- 1000
times <- list(min = 3000, max = 11250) # min = 3000 to avoid pastoral dates
times <- times[[2]]:times[[1]]


df.sard <- as.c14_date_list(SARD) |>
  rename(labnr = Lab.ID) |>
  filter(is.na(c14age)==FALSE &
          is.na(c14std)==FALSE) |>
  filter(c14age < max(times) & c14age > min(times)) |>
  c14bazAAR::remove_duplicates()
dens1.cal <- rcarbon::calibrate(x=df.sard$c14age, errors=df.sard$c14std)

DK.spd = spd(dens1.cal,timeRange=c(max(times),min(times)))

emedyd.spd=stackspd(x=dens1.cal,
                    group=df.sard$Biome,
                    timeRange=c(12000,4000),
                    runm=50,verbos=FALSE)


nevents <- 786
nsamples <- 10000
sim_SA.a <- simulate_event_counts(process = DK.spd$grid$PrDens,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)


# Plot the process
All_process <- ggplot()+
  geom_line(aes(y = DK.spd$grid$PrDens, x = times))+
  labs(x = "", y = "Process")+
  scale_x_reverse()
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
All_REC <- ggplot()+
  geom_bar(aes(x = sim_SA.a$counts$Timestamps, y = sim_SA.a$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  labs(x = "", y = "REC")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
All_RECE <- plot_count_ensemble.mod(count_ensemble = sim_SA.a$count_ensemble,
                    times = sim_SA.a$new_times,
                    use_ggplot2 = T)

# Combine plots
plot_grid(All_process,All_REC,All_RECE, cols = 1)

```

```{r}
nintervals <- 1000
times <- list(min = 3000, max = 11250)
times <- times[[2]]:times[[1]]


df.sard <- as.c14_date_list(SARD) |>
  rename(labnr = Lab.ID) |>
  filter(is.na(c14age)==FALSE &
         ( is.na(c14std)==FALSE)) |>
  filter((c14age < max(times) & c14age > min(times)),
    (culture == "Oakhurst" | culture == "Wilton")) |>
  c14bazAAR::remove_duplicates()
dens1.cal <- rcarbon::calibrate(x=df.sard$c14age, errors=df.sard$c14std)


DK.spd = spd(dens1.cal,timeRange=c(max(times),min(times)))


nevents <- 335
nsamples <- 10000
sim_SA.a_tech <- simulate_event_counts(process = DK.spd$grid$PrDens,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)

# Plot the process
All_process_tech <- ggplot()+
  geom_line(aes(y = DK.spd$grid$PrDens, x = times))+
  labs(x = "", y = "Process")+
  scale_x_reverse()+
  scale_y_continuous(breaks = c(0,0.02,0.04,0.06,0.08))+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
All_REC_tech <- ggplot()+
  geom_bar(aes(x = sim_SA.a_tech$counts$Timestamps, y = sim_SA.a_tech$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  scale_y_continuous(breaks = c(0,1.00,2.00), labels = c("0.00", "1.00", "2.00"))+
  labs(x = "", y = "REC")+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
All_RECE_tech <- plot_count_ensemble.mod(count_ensemble = 
                                           sim_SA.a_tech$count_ensemble,
                    times = sim_SA.a_tech$new_times,
                    use_ggplot2 = T)

# Combine plots
plot_grid(All_process_tech,All_REC_tech,All_RECE_tech, cols = 1)
```

```{r}
max_time <- min(max(sim_SA.a_tech$new_times), max(sim_SA.a$new_times))
min_time <- max(min(sim_SA.a_tech$new_times), min(sim_SA.a$new_times))

nsamples <- 10000
Y <- sim_SA.a_tech$count_ensemble[which(sim_SA.a_tech$new_times<max_time &
                                      sim_SA.a_tech$new_times>min_time),]
x1 <- sim_SA.a$count_ensemble[which(sim_SA.a$new_times<max_time &
                                      sim_SA.a$new_times>min_time),]

n <- dim(Y)[1]
x0 <- rep(1, n)

# compile covariate with intercept and all x1 generations
X <- matrix(nrow = n, ncol = nsamples*2)
x1.c <- 1
for(i in 1:20000){
  if(i %% 2 != 0) {
    X[,i] <- x0
  } else {
    X[,i] <- x1[,x1.c]
    x1.c <- x1.c + 1
  }
}
```

```{r}
set.seed(11)
startvals <- c(0,0)
startscales <- c(0.1, 0.002)

#startvals <- c(0,0,rep(0.1, nrow(Y)))
#startscales <- c(0.1, 0.0002, rep(0.5, nrow(Y)))

mcmc_samples_adapt <- chronup::regress(Y = Y,
                            X = X,
                            model = "pois",
                            startvals = startvals,
                            scales = startscales,
                            adapt = T)

burnin <- floor(dim(mcmc_samples_adapt$samples)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$samples)[1], 1)
new_startvals <- colMeans(mcmc_samples_adapt$samples[indeces,])

burnin <- floor(dim(mcmc_samples_adapt$scales)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$scales)[1], 1)
new_startscales <- colMeans(mcmc_samples_adapt$scales[indeces,])

# Compute model with adjusted parameters
mcmc_samples <- chronup::regress(Y = Y,
                        X = X,
                        model = "pois",
                        startvals = new_startvals,
                        scales = new_startscales,
                        adapt = F)

head(mcmc_samples)

plot(mcmc_samples[, 2], type = "l")

# Create plot for posterior distribution outlining 85% credible interval
quant.1 <- quantile(mcmc_samples[,2], probs = c(0.075, 0.5, 0.925))
plot(density(mcmc_samples[, 2]),
     xlab = "Posterior Estimate")
abline(v = quant.1[1], col = "red")
abline(v = quant.1[3], col = "red")
abline(v = quant.1[2], col = "blue")

# Test probability that posterior estimate is greater than 0
as.data.frame(mcmc_samples[,2]) |>
  dplyr::summarize(prob_greater_0 = mean(mcmc_samples[,2] > 0))
```

# Figure 5

## A: Radiocarbon

```{r}
nintervals <- 1000
times <- SARD |> 
  filter(culture=="Oakhurst") |>
  summarize(quant1 = quantile(c14age, 0.05), 
            quant2 = quantile(c14age, 0.95))
times <- round(times[[2]]):round(times[[1]])

df.sard <- as.c14_date_list(SARD) |>
  rename(labnr = Lab.ID) |>
  filter(is.na(c14age)==FALSE &
          is.na(c14std)==FALSE) |>
  filter(c14age < max(times) & c14age > min(times)) |>
  c14bazAAR::remove_duplicates()
dens1.cal <- rcarbon::calibrate(x=df.sard$c14age, errors=df.sard$c14std)


DK.spd = spd(dens1.cal,timeRange=c(max(times),min(times)))


nevents <- 250
nsamples <- 10000
sim_SA.oak_radio <- simulate_event_counts(process = DK.spd$grid$PrDens,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)

# Plot the process
Oak_process_radio <- ggplot()+
  geom_line(aes(y = DK.spd$grid$PrDens, x = times))+
  labs(x = "", y = "Process")+
  scale_x_reverse()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
Oak_REC_radio <- ggplot()+
  geom_bar(aes(x = sim_SA.oak_radio$counts$Timestamps, 
               y = sim_SA.oak_radio$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  labs(x = "", y = "REC")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
Oak_RECE_radio <- plot_count_ensemble.mod(count_ensemble = 
                                            sim_SA.oak_radio$count_ensemble,
                    times = sim_SA.oak_radio$new_times,
                    use_ggplot2 = T)

# Combine plots
plot_grid(Oak_process_radio,Oak_REC_radio,Oak_RECE_radio, ncol = 1)

```

## B: Oakhurst Technology

#### Create the process that defines the frequency of Oakhurst technology

```{r}
culture_0 = "Oakhurst"
# Define which of the above segments of South Africa
region <- as.c14_date_list(SARD)

# Define cultures based on calibrated data
SA.cal.cult <- region |>
  dplyr::filter(c14age < max(times) &
                  c14age > min(times)) |>
  c14bazAAR::calibrate()

# I need to loop thrugh calibrated dates
## In calrange, if within date_range_SA 'AND' Oakhurst, 1; else, 0
### Store in matrix, for all dates from date_range_SA
#### Add rowwise at end, +1 if overlaps


# Assign dataframe to store dates and names (1 or a 0)
culture.df <- as.data.frame(matrix(nrow=length(0:18000),
                                  ncol=
                                    length(unique(region$site))))

# Assign date values to data frame
# Standardize so I can index data frame by time period
culture.df[,1] <- seq(0:18000)

for(i in 1:dim(SA.cal.cult)[1]){
  culture1 <- SA.cal.cult[i,"culture"]
  if(culture1 == culture_0){
    culture.df[c(seq(min(SA.cal.cult$calrange[[i]]$from),
            max(SA.cal.cult$calrange[[i]]$to),
            1)),
            i+1] <- 1
  } else {
    culture.df[c(seq(min(SA.cal.cult$calrange[[i]]$from),
            max(SA.cal.cult$calrange[[i]]$to),
            1)),
            i+1] <- 0
  }
}

# COnvert all NA to 0 since this is not recorded as culture period
culture.df[is.na(culture.df)] <- 0

x3 <- rowSums(culture.df[,-1])
plot(x = 1:length(x3),
     y = x3,
     type="l")
```

#### Apply the process to *chronup* to create RECE

```{r}
nintervals <- 1000
times <- SARD |> 
  filter(culture=="Oakhurst") |> 
  summarize(quant1 = quantile(c14age, 0.05), 
            quant2 = quantile(c14age, 0.95))
times <- round(times[[2]]):round(times[[1]])

process <- x3[max(times):min(times)]
nevents <- 119
nsamples <- 10000
sim_nast.oak <- simulate_event_counts(process = process,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)

# Plot the process
Oak_process_tech <- ggplot()+
  geom_line(aes(y = x3[min(times):max(times)], x = times))+
  labs(x = "", y = "Process")+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
Oak_REC_tech <- ggplot()+
  geom_bar(aes(x = sim_nast.oak$counts$Timestamps, y = sim_nast.oak$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  labs(x = "", y = "REC")+
    theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
Oak_RECE_tech <- plot_count_ensemble.mod(count_ensemble = 
                                           sim_nast.oak$count_ensemble,
                    times = sim_nast.oak$new_times,
                    use_ggplot2 = T)

# Combine plots
plot_grid(Oak_process_tech,Oak_REC_tech,Oak_RECE_tech, cols = 1)
```

# Figure 6: Posterior Distribution

```{r}
max_time <- min(max(sim_nast.oak$new_times), max(sim_SA.oak_radio$new_times))
min_time <- max(min(sim_nast.oak$new_times), min(sim_SA.oak_radio$new_times))

nsamples <- 10000

Y <- sim_nast.oak$count_ensemble[which(sim_nast.oak$new_times<max_time &
                                      sim_nast.oak$new_times>min_time),]
x1 <- sim_SA.oak_radio$count_ensemble[which(sim_SA.oak_radio$new_times<max_time &
                                      sim_SA.oak_radio$new_times>min_time),]

n <- dim(Y)[1]
x0 <- rep(1, n)

# compile covariate with intercept and all x1 generations
X <- matrix(nrow = n, ncol = nsamples*2)
x1.c <- 1
for(i in 1:20000){
  if(i %% 2 != 0) {
    X[,i] <- x0
  } else {
    X[,i] <- x1[,x1.c]
    x1.c <- x1.c + 1
  }
}
```

```{r}
set.seed(2222)
startvals <- c(0,0)
startscales <- c(0.1, 0.002)

#startvals <- c(0,0,rep(.1, nrow(Y)))
#startscales <- c(0.1, 0.0002, rep(0.5, nrow(Y)))

mcmc_samples_adapt <- chronup::regress(Y = Y,
                            X = X,
                            model = "pois",
                            startvals = startvals,
                            scales = startscales,
                            adapt = T)

burnin <- floor(dim(mcmc_samples_adapt$samples)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$samples)[1], 1)
new_startvals <- colMeans(mcmc_samples_adapt$samples[indeces,])

burnin <- floor(dim(mcmc_samples_adapt$scales)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$scales)[1], 1)
new_startscales <- colMeans(mcmc_samples_adapt$scales[indeces,])

# Compute model with adjusted parameters
mcmc_samples <- chronup::regress(Y = Y,
                        X = X,
                        model = "pois",
                        startvals = new_startvals,
                        scales = new_startscales,
                        adapt = F)

head(mcmc_samples)

plot(mcmc_samples[, 2], type = "l")

# Create plot for posterior distribution outlining 85% credible interval
quant.1 <- quantile(mcmc_samples[,2], probs = c(0.075, 0.5, 0.925))
plot(density(mcmc_samples[, 2]),
     xlab = "Posterior Estimate")
abline(v = quant.1[1], col = "red")
abline(v = quant.1[3], col = "red")
abline(v = quant.1[2], col = "blue")

# Test probability that posterior estimate is greater than 0
as.data.frame(mcmc_samples[,2]) |>
  dplyr::summarize(prob_greater_0 = mean(mcmc_samples[,2] > 0))

```

# Figure 7

## A: Radiocarbon

```{r}
nintervals <- 1000
times <- SARD |> 
  filter(culture=="Wilton") |> 
  summarize(quant1 = quantile(c14age, 0.05), 
            quant2 = quantile(c14age, 0.95))
times <- round(times[[2]]):round(times[[1]])

df.sard <- as.c14_date_list(SARD) |>
  rename(labnr = Lab.ID) |>
  filter(is.na(c14age)==FALSE &
          is.na(c14std)==FALSE) |>
  filter(c14age < max(times) & c14age > min(times)) |>
  filter(Species != "Homo sapiens") |>
  c14bazAAR::remove_duplicates()

dens1.cal <- rcarbon::calibrate(x=df.sard$c14age, errors=df.sard$c14std)


DK.spd = spd(dens1.cal,timeRange=c(max(times),min(times)))


nevents <- 517
nsamples <- 10000
sim_SA <- simulate_event_counts(process = DK.spd$grid$PrDens,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)


# Plot the process
Wilt_process_radio <- ggplot()+
  geom_line(aes(y = DK.spd$grid$PrDens, x = times))+
  scale_x_reverse()+
  labs(x = "", y = "Process")+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
Wilt_REC_radio <- ggplot()+
  geom_bar(aes(x = sim_SA$counts$Timestamps, y = sim_SA$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  labs(x = "", y = "REC")+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
Wilt_RECE_radio <- plot_count_ensemble.mod(count_ensemble = sim_SA$count_ensemble,
                    times = sim_SA$new_times,
                    use_ggplot2 = T)



# Combine plots
plot_grid(Wilt_process_radio,Wilt_REC_radio,Wilt_RECE_radio, ncol = 1)

```

## B: Wilton Technology

#### Create the process that defines the frequency of Wilton technology

```{r}
culture_0 = "Wilton"
# Define which of the above segments of South Africa
region <- as.c14_date_list(SARD)

# Define cultures based on calibrated data
SA.cal.cult <- region |>
  dplyr::filter(c14age < max(times) &
                  c14age > min(times)) |>
  c14bazAAR::calibrate()

# I need to loop thrugh calibrated dates
## In calrange, if within date_range_SA 'AND' Oakhurst, 1; else, 0
### Store in matrix, for all dates from date_range_SA
#### Add rowwise at end, +1 if overlaps


# Assign dataframe to store dates and names (1 or a 0)
culture.df <- as.data.frame(matrix(nrow=length(0:18000),
                                  ncol=
                                    length(unique(region$site))))

# Assign date values to data frame
# Standardize so I can index data frame by time period
culture.df[,1] <- seq(0:18000)

for(i in 1:dim(SA.cal.cult)[1]){
  culture1 <- SA.cal.cult[i,"culture"]
  if(culture1 == culture_0){
    culture.df[c(seq(min(SA.cal.cult$calrange[[i]]$from),
            max(SA.cal.cult$calrange[[i]]$to),
            1)),
            i+1] <- 1
  } else {
    culture.df[c(seq(min(SA.cal.cult$calrange[[i]]$from),
            max(SA.cal.cult$calrange[[i]]$to),
            1)),
            i+1] <- 0
  }
}

# Convert all NA to 0 since this is not recorded as culture period
culture.df[is.na(culture.df)] <- 0

x3 <- rowSums(culture.df[,-1])
plot(x = 0:18000,
     y = x3,
     type="l")
```

#### Apply the process to *chronup* to create RECE

```{r}
nintervals <- 1000
times <- SARD |> 
  filter(culture=="Wilton") |> 
  summarize(quant1 = quantile(c14age, 0.05), 
            quant2 = quantile(c14age, 0.95))
times <- times[[2]]:times[[1]]

process <- x3[max(times):min(times)]
nevents <- 188
nsamples <- 10000
sim_nast <- simulate_event_counts(process = process,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)




# Plot the process
Wilt_process_tech <- ggplot()+
  geom_line(aes(y = x3[max(times):min(times)], x = times))+
  labs(x = "", y = "Process")+
  scale_x_reverse()+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
Wilt_REC_tech <- ggplot()+
  geom_bar(aes(x = sim_nast$counts$Timestamps, y = sim_nast$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  labs(x = "", y = "REC")+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
Wilt_RECE_tech <- plot_count_ensemble.mod(count_ensemble = sim_nast$count_ensemble,
                    times = sim_nast$new_times,
                    use_ggplot2 = T)

# Combine plots
plot_grid(Wilt_process_tech,Wilt_REC_tech,Wilt_RECE_tech, cols = 1)
```

# Figure 8: Posterior Distribution

```{r}
max_time <- min(max(sim_nast$new_times), max(sim_SA$new_times))
min_time <- max(min(sim_nast$new_times), min(sim_SA$new_times))

nsamples <- 10000


Y <- sim_nast$count_ensemble[which(sim_nast$new_times<max_time &
                                      sim_nast$new_times>min_time),]
x1 <- sim_SA$count_ensemble[which(sim_SA$new_times<max_time &
                                      sim_SA$new_times>min_time),]

n <- dim(Y)[1]
x0 <- rep(1, n)

# compile covariate with intercept and all x1 generations
X <- matrix(nrow = n, ncol = nsamples*2)
x1.c <- 1
for(i in 1:20000){
  if(i %% 2 != 0) {
    X[,i] <- x0
  } else {
    X[,i] <- x1[,x1.c]
    x1.c <- x1.c + 1
  }
}

```

```{r}
set.seed(3333)
startvals <- c(0,0)
startscales <- c(0.1, 0.002)


startvals <- c(0,0,rep(.1, nrow(Y)))
startscales <- c(0.1, 0.0002, rep(0.5, nrow(Y)))

mcmc_samples_adapt <- chronup::regress(Y = Y,
                            X = X,
                            model = "nb",
                            startvals = startvals,
                            scales = startscales,
                            adapt = T)

burnin <- floor(dim(mcmc_samples_adapt$samples)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$samples)[1], 1)
new_startvals <- colMeans(mcmc_samples_adapt$samples[indeces,])

burnin <- floor(dim(mcmc_samples_adapt$scales)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$scales)[1], 1)
new_startscales <- colMeans(mcmc_samples_adapt$scales[indeces,])

mcmc_samples <- chronup::regress(Y = Y,
                        X = X,
                        model = "pois",
                        startvals = new_startvals,
                        scales = new_startscales,
                        adapt = F)

head(mcmc_samples)

plot(mcmc_samples[, 2], type = "l")

quant.1 <- quantile(mcmc_samples[,2], probs = c(0.075, 0.5, 0.925))
plot(density(mcmc_samples[, 2]),
     xlab = "Posterior Estimate")
abline(v = quant.1[1], col = "red")
abline(v = quant.1[3], col = "red")
abline(v = quant.1[2], col = "blue")

# Test probability that it lies above 0
as.data.frame(mcmc_samples[,2]) |>
  dplyr::summarize(prob_greater_0 = mean(mcmc_samples[,2] > 0))
```
