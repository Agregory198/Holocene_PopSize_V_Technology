---
title: "Population size Versus the frequency of Oakhurst and Wilton technology"
author: "Alex Gregory"
format: pdf
editor: visual
---

```{r}
library(chronup)
library(rstanarm)
library(bayesrules)
library(bayesplot)
library(tidyverse)
library(tidybayes)
library(broom.mixed)


library(geodata)

library(nimble)
library(ggplot2)
library(cowplot)
library(ggpubr)
library(tidyr)
library(dplyr)
library(chronup)
library(abind)
library(clam)
library(pastclim)
library(tibble)
library(c14bazAAR)
library(MCMCvis)
library(chronup)
library(rcarbon)
# Map
library(tmap)
library(ggmap)
library(raster)
library(broom)
library(cowplot)
# Parallel
library(foreach)
library(doParallel)
# Bayes
library(bayesrules)
library(bayesplot)
library(tidyverse)
library(tidybayes)
library(broom.mixed)
library(rstanarm)
```

```{r}
plot_count_ensemble.mod <- function (count_ensemble, times, use_ggplot2 = FALSE, axis_x_res = 100, 
    axis_y_res = 1) 
{
    nevents <- sum(count_ensemble[, 1])
    event_count_freqs <- t(apply(count_ensemble, 1, chronup::tabulate_freqs, 
        nevents = nevents))
    max_count <- chronup::find_max_count(event_count_freqs)
    event_count_freqs_na <- event_count_freqs
    event_count_freqs_na[which(event_count_freqs_na == 0)] <- NA
    event_count_freqs_na <- event_count_freqs_na[, 2:max_count]
    if (use_ggplot2) {
        ggplot2_installed <- requireNamespace("ggplot2", quietly = TRUE)
        if (ggplot2_installed) {
            ncols <- dim(event_count_freqs_na)[2]
            event_count_freqs_df <- as.data.frame(cbind(times, 
                event_count_freqs_na))
            colnames <- c("x", as.character(1:ncols))
            names(event_count_freqs_df) <- colnames
            event_count_freqs_df_long <- tidyr::pivot_longer(event_count_freqs_df, 
                cols = 2:ncols, names_to = "y", values_to = "frequency")
            p <- ggplot2::ggplot(data = event_count_freqs_df_long, 
                mapping = ggplot2::aes(x = .data$x, y = .data$y)) + 
                ggplot2::geom_raster(mapping = ggplot2::aes(fill = frequency)) + 
                ggplot2::scale_fill_viridis_c(option = "B", na.value = grDevices::rgb(0, 
                  0, 0, 0), begin = 0.15, alpha = 0.9, trans = "log") + 
                ggplot2::labs(x = "Time", y = "Count") + # remove legend+
            scale_x_reverse() +
              theme_bw() + theme(panel.border = element_blank(),
                                 #panel.grid.major = element_blank(),
                                 panel.grid.minor = element_blank(),
                                 legend.position = "none",
                                 text = element_text(size = 20))# reverse x-axis
            print(p)
            return(p)
        }
        else {
            stop("ggplot2 not installed.")
        }
    }
    else {
        image(x = 1:dim(event_count_freqs_na)[1], y = 1:dim(event_count_freqs_na)[2], 
            z = event_count_freqs_na, useRaster = T, col = grDevices::hcl.colors(n = 10, 
                palette = "viridis", alpha = 0.9), axes = FALSE, 
            xlab = "Time", ylab = "Count")
        axis_y_at <- seq(1, dim(event_count_freqs_na)[2], axis_y_res)
        axis_x_at <- seq(1, dim(event_count_freqs_na)[1], axis_x_res)
        axis(1, at = axis_x_at, labels = times[axis_x_at])
        axis(2, at = axis_y_at)
    }
    return()
}
```

```{r}
dir <- here::here()
```

```{r}
SARD.df <- read.csv(paste0(dir,"/data/SARD_Mar2021_14C.csv"))

SARD.df |>
  rename(site = X.Site,
         c14age = Date,
         c14std = Uncertainty,
         culture = Archaeological.Sub.chronology,
         lat = DecdegS,
         lon = DecdegE) |>
  mutate_at(c("c14age", "c14std"), as.numeric) -> SARD

##########################

my_map.df <- SARD.df |> dplyr::filter(!is.na(DecdegE))

sard.map <- SARD.df |>
  mutate(Date = as.numeric(Date)) |>
  filter(Date < 12000 & Date > 4000)

sard.map |>
  group_by(Archaeological.Sub.chronology) |>
  summarize(n())

sard.map |> dplyr::select(X.Site, DecdegS, DecdegE, 
                          Country, Biome,
                          Date, Uncertainty, 
                          Archaeological.Sub.chronology) |>
  rename(site = X.Site, lat = DecdegS, lon = DecdegE,
         `Technological Complex` = Archaeological.Sub.chronology)-> SARD.out
write.csv(SARD.out, paste0(dir,"/data/Radiocarbon_data_uncalib.csv"), sep = ",")


```

# Export all relevant databases for OxCal

```{r}
# Select all Oakhurst and Wilton
SARD |> 
  filter(c14age < max(SARD$c14age[which(culture == "Oakhurst")]) &
           c14age > min(SARD$c14age[which(culture == "Wilton")])) |>
  
  filter(Species != "Homo sapiens") -> SARD_Oak_Wil

# Select and trim Oakhurst dates
SARD_Oak_Wil |>
  filter(culture == "Oakhurst") |>
  filter(c14age > quantile(c14age, 0.05) &
           c14age < quantile(c14age, 0.95)) -> SARD_Oak_trimmed

# Select and trim Wilton dates
SARD_Oak_Wil |>
  filter(culture == "Wilton") |>
  filter(c14age > quantile(c14age, 0.05) &
           c14age < quantile(c14age, 0.95)) -> SARD_Wil_trimmed


# Select all data based on Oakhurst and Wilton time periods
SARD |> 
  filter(c14age < max(SARD_Oak_trimmed$c14age) &
                 c14age > min(SARD_Wil_trimmed$c14age)) -> SARD_All

SARD_All |>
  filter(c14age < max(SARD_Oak_trimmed$c14age) &
                 c14age > min(SARD_Oak_trimmed$c14age)) -> SARD_All_Oak

SARD_All |>
  filter(c14age < max(SARD_Wil_trimmed$c14age) &
                 c14age > min(SARD_Wil_trimmed$c14age)) -> SARD_All_Wil





```

## Winter Rainfall Zone

```{r}
# All dates within Oakhurst range
SARD_All_Oak |> 
  filter(RFZ == "W") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Oak_RFZ
write.csv(SARD_All_Oak_RFZ, paste0(dir,"/data/SARD_All_Oak_WRZ.csv"))

# Only sites associated with Oakhurst
SARD_Oak_trimmed |> 
  filter(RFZ == "W") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Oak_RFZ
write.csv(SARD_Oak_RFZ, paste0(dir,"/data/SARD_Oak_WRZ.csv"))


# All dates within Wilton range
SARD_All_Wil |> 
  filter(RFZ == "W") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Wil_RFZ
write.csv(SARD_All_Wil_RFZ, paste0(dir,"/data/SARD_All_Wil_WRZ.csv"))

# Only sites associated with Wilton
SARD_Wil_trimmed |> 
  filter(RFZ == "W") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Wil_RFZ
write.csv(SARD_Wil_RFZ, paste0(dir,"/data/SARD_Wil_WRZ.csv"))
```

## Summer Rainfall Zone

```{r}
# All dates within Oakhurst range
SARD_All_Oak |> 
  filter(RFZ == "S") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Oak_RFZ
write.csv(SARD_All_Oak_RFZ, paste0(dir,"/data/SARD_All_Oak_SRZ.csv"))

# Only sites associated with Oakhurst
SARD_Oak_trimmed |> 
  filter(RFZ == "S") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Oak_RFZ
write.csv(SARD_Oak_RFZ, paste0(dir,"/data/SARD_Oak_SRZ.csv"))


# All dates within Wilton range
SARD_All_Wil |> 
  filter(RFZ == "S") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Wil_RFZ
write.csv(SARD_All_Wil_RFZ, paste0(dir,"/data/SARD_All_Wil_SRZ.csv"))

# Only sites associated with Wilton
SARD_Wil_trimmed |> 
  filter(RFZ == "S") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Wil_RFZ
write.csv(SARD_Wil_RFZ, paste0(dir,"/data/SARD_Wil_SRZ.csv"))
```

## Year-round Rainfall Zone

```{r}
# All dates within Oakhurst range
SARD_All_Oak |> 
  filter(RFZ == "Y") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Oak_RFZ
write.csv(SARD_All_Oak_RFZ, paste0(dir,"/data/SARD_All_Oak_YRZ.csv"))

# Only sites associated with Oakhurst
SARD_Oak_trimmed |> 
  filter(RFZ == "Y") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Oak_RFZ
write.csv(SARD_Oak_RFZ, paste0(dir,"/data/SARD_Oak_YRZ.csv"))


# All dates within Wilton range
SARD_All_Wil |> 
  filter(RFZ == "Y") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_All_Wil_RFZ
write.csv(SARD_All_Wil_RFZ, paste0(dir,"/data/SARD_All_Wil_YRZ.csv"))

# Only sites associated with Wilton
SARD_Wil_trimmed |> 
  filter(RFZ == "Y") |>
  dplyr::select(site, Lab.ID, c14age,
                c14std, culture, lat, lon, Material.dated) |>
  arrange(desc(c14age)) -> SARD_Wil_RFZ
write.csv(SARD_Wil_RFZ, paste0(dir,"/data/SARD_Wil_YRZ.csv"))
```

### Site Selection Based on Oakhurst and Wilton Technology

```{r}
#| include: false


SARD |> group_by(site, culture) |> filter(culture == "Oakhurst" | culture == "Wilton") |> 
  dplyr::distinct(site, culture) |>
  mutate(cult = ifelse(culture == "Oakhurst", 1, 2)) |>
  group_by(site) |>
  summarize(s = sum(cult)) |>
  filter(s == 3) -> Sites_with_both

SARD |>
  dplyr::filter(site %in% 
                  c("Apollo 11 cave",
                    "Blydefontein",
                    "Boomplaas",
                    "Buffelskloof",
                    #"Byneskranskop 1",
                    "Elands Bay Cave",
                    "Grassridge",
                    "Havens Cave",
                    "Jubilee Shelter",
                    #"Kangkara Cave",
                    #"Matjies River",
                    "Melkhoutboom",
                    "Nelson Bay Cave",
                    "Oakhurst",
                    "Rose Cottage Cave",
                    "Sehonghong",
                    "Sophiso",
                    "Tloutle",
                    "Wilton Large Rock Shelter")) |>
  filter(c14age < max(SARD_Oak_trimmed$c14age) &
                 c14age > min(SARD_Wil_trimmed$c14age)) |>
  group_by(site, culture) |>
  summarize(c14Count = n()) -> tu


library(rnaturalearth)
library(sf)
south_africa <- ne_countries(scale = "medium", 
                             country = "South Africa", 
                             returnclass = "sf")

SARD |>
  filter(site %in% c("Elands Bay Cave", "Nelson Bay Cave",
                     "Boomplaas", "Rose Cottage Cave", "Sehonghong")) |>
  distinct(lat, lon, site) |>
  ggplot()+
  geom_sf(data = south_africa) +
  geom_point(aes(x = lon, y = lat, color = site))
```

```{r compare_Elands_Nelson}
#| include: false


Nel <- read.delim(paste0(dir,"/data/NonLithics_NBC.txt"), sep = ",")
Nel <- tibble(
  Artifact = c("Beads", "Beads/excavatedArea", "Scraper"),
  `22-62` = c(458, 0.132, 105.9),
  `64-139` = c(53, 0.051, 63.5),
  `135-148` = c(23, 0.150, 5.3)
)

Nel <- tibble(
  Artifact = c("Beads", "Ochre", "Processing Tools", "Fish Gorges", "VOlume"),
  IC = c(1,NA,NA,0,NA),
  BSC = c(0,NA,NA,0,NA),
  RA = c(0,NA,NA,6,NA),
  RB = c(1,NA,NA,4,NA),
  J = c(0,NA,NA,3,NA),
  BSBJ = c(0,NA,NA,22,NA),
  CS = c(1,NA,NA,25,NA),
  GSL = c(1,NA,NA,1,NA)
)


El <- tibble(
  Artifact = c("Beads", "Ochre", "Processing Tools", "Fish Gorges", "VOlume"),
  
  `10` = c(6.8, 2.3, 0.9, 6.5, 3.1),
  `11-13` = c(19.2, 4.1, 1.8, 336.3, 2.4),
  `14-15` = c(60.6, 16.3, 2.5, 1.5, 2.7),
  `16` = c(68, 25, 2.8, 0, 1),
  `17-19` = c(37.8, 4.3, 1.4, 0, 2.3))

#### Scrapppppz
SARD.hol <- SARD |> filter(c14age < 16450 & c14age > 2220 &
                           site == "Elands Bay Cave") 
caldates <- rcarbon::calibrate(SARD.hol$c14age, SARD.hol$c14std,
                               calCurves = "intcal20", ids = SARD.hol$Lab.ID)

bins <- binPrep(SARD.hol$site, ages = caldates, h = 100)

randates <- sampleDates(caldates, bins = bins, nsim = 1000, verbose = F)


SARD.ckde <- ckde(randates, timeRange = c(17000, 2000), bw = 200)

plot(SARD.ckde, type = "multiline")

plot(spd(caldates, bins, timeRange = c(17000,2000)), add = F)
```

# Figure 2: Example Summed Distribution

```{r}
df.sard <- as.c14_date_list(SARD) |>
  rename(labnr = Lab.ID) |>
  filter(is.na(c14age)==FALSE &
          is.na(c14std)==FALSE) |>
  filter(site == "Boomplaas") |>
  c14bazAAR::remove_duplicates()
dens1.cal <- rcarbon::calibrate(x=df.sard$c14age, errors=df.sard$c14std)

# plot individual dates for elands bay cave
multiplot(subset(dens1.cal, BP<15000&BP>2000, p=0.01), label=F)

# plot cumulative sum distribution
DK.spd = spd(dens1.cal,timeRange=c(15000,2000))
plot(DK.spd)



```

# Figure 3: Example Datatset for Process and REC

```{r}
samp.int <- 2000
samp.times <- 10000:8001
samp.beta <- 0.04
samp.process <- sqrt(samp.beta*(1:samp.int))
samp.nevents <- 500

samp.nsamples <- 20000
samp.sim_sequences <- simulate_event_counts(process = samp.process,
                            times = samp.times,
                            nevents = samp.nevents,
                            nsamples = samp.nsamples,
                            parallel = T)



plot(y = samp.process,
    x = samp.times,
    type = "l",
    xlim = c(samp.times[1], samp.times[length(samp.times)]),
    xlab = "Time",
    ylab = "Process Level")



plot(y = samp.sim_sequences$counts$Count,
    x = samp.sim_sequences$counts$Timestamps,
    type = "h",
    xlim = c(samp.times[1], samp.times[length(samp.times)]),
    xlab = "Time",
    ylab = "Count")
grid()


plot_count_ensemble.mod(count_ensemble = samp.sim_sequences$count_ensemble,
                    times = (samp.sim_sequences$new_times),
                    use_ggplot2 = T)
```

# Figure 4: RECE for 12-3 ka cal. BP (radiocarbon)

```{r}
nintervals <- 1000
times <- list(min = 3000, max = 11250) # min = 3000 to avoid pastoral dates
times <- times[[2]]:times[[1]]


df.sard <- as.c14_date_list(SARD) |>
  rename(labnr = Lab.ID) |>
  filter(is.na(c14age)==FALSE &
          is.na(c14std)==FALSE) |>
  filter(c14age < max(times) & c14age > min(times)) |>
  c14bazAAR::remove_duplicates()
dens1.cal <- rcarbon::calibrate(x=df.sard$c14age, errors=df.sard$c14std)

DK.spd = spd(dens1.cal,timeRange=c(max(times),min(times)))

emedyd.spd=stackspd(x=dens1.cal,
                    group=df.sard$Biome,
                    timeRange=c(12000,4000),
                    runm=50,verbos=FALSE)


nevents <- 786
nsamples <- 10000
sim_SA.a <- simulate_event_counts(process = DK.spd$grid$PrDens,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)


# Plot the process
All_process <- ggplot()+
  geom_line(aes(y = DK.spd$grid$PrDens, x = times))+
  labs(x = "", y = "Process")+
  scale_x_reverse()
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
All_REC <- ggplot()+
  geom_bar(aes(x = sim_SA.a$counts$Timestamps, y = sim_SA.a$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  labs(x = "", y = "REC")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
All_RECE <- plot_count_ensemble.mod(count_ensemble = sim_SA.a$count_ensemble,
                    times = sim_SA.a$new_times,
                    use_ggplot2 = T)

# Combine plots
plot_grid(All_process,All_REC,All_RECE, cols = 1)

```

```{r}
nintervals <- 1000
times <- list(min = 3000, max = 11250)
times <- times[[2]]:times[[1]]


df.sard <- as.c14_date_list(SARD) |>
  rename(labnr = Lab.ID) |>
  filter(is.na(c14age)==FALSE &
         ( is.na(c14std)==FALSE)) |>
  filter((c14age < max(times) & c14age > min(times)),
    (culture == "Oakhurst" | culture == "Wilton")) |>
  c14bazAAR::remove_duplicates()
dens1.cal <- rcarbon::calibrate(x=df.sard$c14age, errors=df.sard$c14std)


DK.spd = spd(dens1.cal,timeRange=c(max(times),min(times)))


nevents <- 335
nsamples <- 10000
sim_SA.a_tech <- simulate_event_counts(process = DK.spd$grid$PrDens,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)

# Plot the process
All_process_tech <- ggplot()+
  geom_line(aes(y = DK.spd$grid$PrDens, x = times))+
  labs(x = "", y = "Process")+
  scale_x_reverse()+
  scale_y_continuous(breaks = c(0,0.02,0.04,0.06,0.08))+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
All_REC_tech <- ggplot()+
  geom_bar(aes(x = sim_SA.a_tech$counts$Timestamps, y = sim_SA.a_tech$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  scale_y_continuous(breaks = c(0,1.00,2.00), labels = c("0.00", "1.00", "2.00"))+
  labs(x = "", y = "REC")+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
All_RECE_tech <- plot_count_ensemble.mod(count_ensemble = 
                                           sim_SA.a_tech$count_ensemble,
                    times = sim_SA.a_tech$new_times,
                    use_ggplot2 = T)

# Combine plots
plot_grid(All_process_tech,All_REC_tech,All_RECE_tech, cols = 1)
```

```{r}
max_time <- min(max(sim_SA.a_tech$new_times), max(sim_SA.a$new_times))
min_time <- max(min(sim_SA.a_tech$new_times), min(sim_SA.a$new_times))

nsamples <- 10000
Y <- sim_SA.a_tech$count_ensemble[which(sim_SA.a_tech$new_times<max_time &
                                      sim_SA.a_tech$new_times>min_time),]
x1 <- sim_SA.a$count_ensemble[which(sim_SA.a$new_times<max_time &
                                      sim_SA.a$new_times>min_time),]

n <- dim(Y)[1]
x0 <- rep(1, n)

# compile covariate with intercept and all x1 generations
X <- matrix(nrow = n, ncol = nsamples*2)
x1.c <- 1
for(i in 1:20000){
  if(i %% 2 != 0) {
    X[,i] <- x0
  } else {
    X[,i] <- x1[,x1.c]
    x1.c <- x1.c + 1
  }
}
```

```{r}
set.seed(11)
startvals <- c(0,0)
startscales <- c(0.1, 0.002)

#startvals <- c(0,0,rep(0.1, nrow(Y)))
#startscales <- c(0.1, 0.0002, rep(0.5, nrow(Y)))

mcmc_samples_adapt <- chronup::regress(Y = Y,
                            X = X,
                            model = "pois",
                            startvals = startvals,
                            scales = startscales,
                            adapt = T)

burnin <- floor(dim(mcmc_samples_adapt$samples)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$samples)[1], 1)
new_startvals <- colMeans(mcmc_samples_adapt$samples[indeces,])

burnin <- floor(dim(mcmc_samples_adapt$scales)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$scales)[1], 1)
new_startscales <- colMeans(mcmc_samples_adapt$scales[indeces,])

# Compute model with adjusted parameters
mcmc_samples <- chronup::regress(Y = Y,
                        X = X,
                        model = "pois",
                        startvals = new_startvals,
                        scales = new_startscales,
                        adapt = F)

head(mcmc_samples)

plot(mcmc_samples[, 2], type = "l")

# Create plot for posterior distribution outlining 85% credible interval
quant.1 <- quantile(mcmc_samples[,2], probs = c(0.075, 0.5, 0.925))
plot(density(mcmc_samples[, 2]),
     xlab = "Posterior Estimate")
abline(v = quant.1[1], col = "red")
abline(v = quant.1[3], col = "red")
abline(v = quant.1[2], col = "blue")

# Test probability that posterior estimate is greater than 0
as.data.frame(mcmc_samples[,2]) |>
  dplyr::summarize(prob_greater_0 = mean(mcmc_samples[,2] > 0))
```

# Figure 5

## A: Radiocarbon

```{r}
nintervals <- 1000
times <- SARD |> 
  filter(culture=="Oakhurst") |>
  summarize(quant1 = quantile(c14age, 0.05), 
            quant2 = quantile(c14age, 0.95))
times <- round(times[[2]]):round(times[[1]])

df.sard <- as.c14_date_list(SARD) |>
  rename(labnr = Lab.ID) |>
  filter(is.na(c14age)==FALSE &
          is.na(c14std)==FALSE) |>
  filter(c14age < max(times) & c14age > min(times)) |>
  c14bazAAR::remove_duplicates()
dens1.cal <- rcarbon::calibrate(x=df.sard$c14age, errors=df.sard$c14std)


DK.spd = spd(dens1.cal,timeRange=c(max(times),min(times)))


nevents <- 250
nsamples <- 10000
sim_SA.oak_radio <- simulate_event_counts(process = DK.spd$grid$PrDens,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)

# Plot the process
Oak_process_radio <- ggplot()+
  geom_line(aes(y = DK.spd$grid$PrDens, x = times))+
  labs(x = "", y = "Process")+
  scale_x_reverse()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
Oak_REC_radio <- ggplot()+
  geom_bar(aes(x = sim_SA.oak_radio$counts$Timestamps, 
               y = sim_SA.oak_radio$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  labs(x = "", y = "REC")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
Oak_RECE_radio <- plot_count_ensemble.mod(count_ensemble = 
                                            sim_SA.oak_radio$count_ensemble,
                    times = sim_SA.oak_radio$new_times,
                    use_ggplot2 = T)

# Combine plots
plot_grid(Oak_process_radio,Oak_REC_radio,Oak_RECE_radio, ncol = 1)

```

## B: Oakhurst Technology

#### Create the process that defines the frequency of Oakhurst technology

```{r}
culture_0 = "Oakhurst"
# Define which of the above segments of South Africa
region <- as.c14_date_list(SARD)

# Define cultures based on calibrated data
SA.cal.cult <- region |>
  dplyr::filter(c14age < max(times) &
                  c14age > min(times)) |>
  c14bazAAR::calibrate()

# I need to loop thrugh calibrated dates
## In calrange, if within date_range_SA 'AND' Oakhurst, 1; else, 0
### Store in matrix, for all dates from date_range_SA
#### Add rowwise at end, +1 if overlaps


# Assign dataframe to store dates and names (1 or a 0)
culture.df <- as.data.frame(matrix(nrow=length(0:18000),
                                  ncol=
                                    length(unique(region$site))))

# Assign date values to data frame
# Standardize so I can index data frame by time period
culture.df[,1] <- seq(0:18000)

for(i in 1:dim(SA.cal.cult)[1]){
  culture1 <- SA.cal.cult[i,"culture"]
  if(culture1 == culture_0){
    culture.df[c(seq(min(SA.cal.cult$calrange[[i]]$from),
            max(SA.cal.cult$calrange[[i]]$to),
            1)),
            i+1] <- 1
  } else {
    culture.df[c(seq(min(SA.cal.cult$calrange[[i]]$from),
            max(SA.cal.cult$calrange[[i]]$to),
            1)),
            i+1] <- 0
  }
}

# COnvert all NA to 0 since this is not recorded as culture period
culture.df[is.na(culture.df)] <- 0

x3 <- rowSums(culture.df[,-1])
plot(x = 1:length(x3),
     y = x3,
     type="l")
```

#### Apply the process to *chronup* to create RECE

```{r}
nintervals <- 1000
times <- SARD |> 
  filter(culture=="Oakhurst") |> 
  summarize(quant1 = quantile(c14age, 0.05), 
            quant2 = quantile(c14age, 0.95))
times <- round(times[[2]]):round(times[[1]])

process <- x3[max(times):min(times)]
nevents <- 119
nsamples <- 10000
sim_nast.oak <- simulate_event_counts(process = process,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)

# Plot the process
Oak_process_tech <- ggplot()+
  geom_line(aes(y = x3[min(times):max(times)], x = times))+
  labs(x = "", y = "Process")+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
Oak_REC_tech <- ggplot()+
  geom_bar(aes(x = sim_nast.oak$counts$Timestamps, y = sim_nast.oak$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  labs(x = "", y = "REC")+
    theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
Oak_RECE_tech <- plot_count_ensemble.mod(count_ensemble = 
                                           sim_nast.oak$count_ensemble,
                    times = sim_nast.oak$new_times,
                    use_ggplot2 = T)

# Combine plots
plot_grid(Oak_process_tech,Oak_REC_tech,Oak_RECE_tech, cols = 1)
```

# Figure 6: Posterior Distribution

```{r}
max_time <- min(max(sim_nast.oak$new_times), max(sim_SA.oak_radio$new_times))
min_time <- max(min(sim_nast.oak$new_times), min(sim_SA.oak_radio$new_times))

nsamples <- 10000

Y <- sim_nast.oak$count_ensemble[which(sim_nast.oak$new_times<max_time &
                                      sim_nast.oak$new_times>min_time),]
x1 <- sim_SA.oak_radio$count_ensemble[which(sim_SA.oak_radio$new_times<max_time &
                                      sim_SA.oak_radio$new_times>min_time),]

n <- dim(Y)[1]
x0 <- rep(1, n)

# compile covariate with intercept and all x1 generations
X <- matrix(nrow = n, ncol = nsamples*2)
x1.c <- 1
for(i in 1:20000){
  if(i %% 2 != 0) {
    X[,i] <- x0
  } else {
    X[,i] <- x1[,x1.c]
    x1.c <- x1.c + 1
  }
}
```

```{r}
set.seed(2222)
startvals <- c(0,0)
startscales <- c(0.1, 0.002)

#startvals <- c(0,0,rep(.1, nrow(Y)))
#startscales <- c(0.1, 0.0002, rep(0.5, nrow(Y)))

mcmc_samples_adapt <- chronup::regress(Y = Y,
                            X = X,
                            model = "pois",
                            startvals = startvals,
                            scales = startscales,
                            adapt = T)

burnin <- floor(dim(mcmc_samples_adapt$samples)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$samples)[1], 1)
new_startvals <- colMeans(mcmc_samples_adapt$samples[indeces,])

burnin <- floor(dim(mcmc_samples_adapt$scales)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$scales)[1], 1)
new_startscales <- colMeans(mcmc_samples_adapt$scales[indeces,])

# Compute model with adjusted parameters
mcmc_samples <- chronup::regress(Y = Y,
                        X = X,
                        model = "pois",
                        startvals = new_startvals,
                        scales = new_startscales,
                        adapt = F)

head(mcmc_samples)

plot(mcmc_samples[, 2], type = "l")

# Create plot for posterior distribution outlining 85% credible interval
quant.1 <- quantile(mcmc_samples[,2], probs = c(0.075, 0.5, 0.925))
plot(density(mcmc_samples[, 2]),
     xlab = "Posterior Estimate")
abline(v = quant.1[1], col = "red")
abline(v = quant.1[3], col = "red")
abline(v = quant.1[2], col = "blue")

# Test probability that posterior estimate is greater than 0
as.data.frame(mcmc_samples[,2]) |>
  dplyr::summarize(prob_greater_0 = mean(mcmc_samples[,2] > 0))

```

# Figure 7

## A: Radiocarbon

```{r}
nintervals <- 1000
times <- SARD |> 
  filter(culture=="Wilton") |> 
  summarize(quant1 = quantile(c14age, 0.05), 
            quant2 = quantile(c14age, 0.95))
times <- round(times[[2]]):round(times[[1]])

df.sard <- as.c14_date_list(SARD) |>
  rename(labnr = Lab.ID) |>
  filter(is.na(c14age)==FALSE &
          is.na(c14std)==FALSE) |>
  filter(c14age < max(times) & c14age > min(times)) |>
  filter(Species != "Homo sapiens") |>
  c14bazAAR::remove_duplicates()

dens1.cal <- rcarbon::calibrate(x=df.sard$c14age, errors=df.sard$c14std)


DK.spd = spd(dens1.cal,timeRange=c(max(times),min(times)))


nevents <- 517
nsamples <- 10000
sim_SA <- simulate_event_counts(process = DK.spd$grid$PrDens,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)


# Plot the process
Wilt_process_radio <- ggplot()+
  geom_line(aes(y = DK.spd$grid$PrDens, x = times))+
  scale_x_reverse()+
  labs(x = "", y = "Process")+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
Wilt_REC_radio <- ggplot()+
  geom_bar(aes(x = sim_SA$counts$Timestamps, y = sim_SA$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  labs(x = "", y = "REC")+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
Wilt_RECE_radio <- plot_count_ensemble.mod(count_ensemble = sim_SA$count_ensemble,
                    times = sim_SA$new_times,
                    use_ggplot2 = T)



# Combine plots
plot_grid(Wilt_process_radio,Wilt_REC_radio,Wilt_RECE_radio, ncol = 1)

```

## B: Wilton Technology

#### Create the process that defines the frequency of Wilton technology

```{r}
culture_0 = "Wilton"
# Define which of the above segments of South Africa
region <- as.c14_date_list(SARD)

# Define cultures based on calibrated data
SA.cal.cult <- region |>
  dplyr::filter(c14age < max(times) &
                  c14age > min(times)) |>
  c14bazAAR::calibrate()

# I need to loop thrugh calibrated dates
## In calrange, if within date_range_SA 'AND' Oakhurst, 1; else, 0
### Store in matrix, for all dates from date_range_SA
#### Add rowwise at end, +1 if overlaps


# Assign dataframe to store dates and names (1 or a 0)
culture.df <- as.data.frame(matrix(nrow=length(0:18000),
                                  ncol=
                                    length(unique(region$site))))

# Assign date values to data frame
# Standardize so I can index data frame by time period
culture.df[,1] <- seq(0:18000)

for(i in 1:dim(SA.cal.cult)[1]){
  culture1 <- SA.cal.cult[i,"culture"]
  if(culture1 == culture_0){
    culture.df[c(seq(min(SA.cal.cult$calrange[[i]]$from),
            max(SA.cal.cult$calrange[[i]]$to),
            1)),
            i+1] <- 1
  } else {
    culture.df[c(seq(min(SA.cal.cult$calrange[[i]]$from),
            max(SA.cal.cult$calrange[[i]]$to),
            1)),
            i+1] <- 0
  }
}

# Convert all NA to 0 since this is not recorded as culture period
culture.df[is.na(culture.df)] <- 0

x3 <- rowSums(culture.df[,-1])
plot(x = 0:18000,
     y = x3,
     type="l")
```

#### Apply the process to *chronup* to create RECE

```{r}
nintervals <- 1000
times <- SARD |> 
  filter(culture=="Wilton") |> 
  summarize(quant1 = quantile(c14age, 0.05), 
            quant2 = quantile(c14age, 0.95))
times <- times[[2]]:times[[1]]

process <- x3[max(times):min(times)]
nevents <- 188
nsamples <- 10000
sim_nast <- simulate_event_counts(process = process,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            parallel = T)




# Plot the process
Wilt_process_tech <- ggplot()+
  geom_line(aes(y = x3[max(times):min(times)], x = times))+
  labs(x = "", y = "Process")+
  scale_x_reverse()+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the REC
Wilt_REC_tech <- ggplot()+
  geom_bar(aes(x = sim_nast$counts$Timestamps, y = sim_nast$counts$Count),
           stat = "identity", width = 10)+
  scale_x_reverse()+
  labs(x = "", y = "REC")+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none",
        text = element_text(size = 20))

# Plot the RECE
Wilt_RECE_tech <- plot_count_ensemble.mod(count_ensemble = sim_nast$count_ensemble,
                    times = sim_nast$new_times,
                    use_ggplot2 = T)

# Combine plots
plot_grid(Wilt_process_tech,Wilt_REC_tech,Wilt_RECE_tech, cols = 1)
```

# Figure 8: Posterior Distribution

```{r}
max_time <- min(max(sim_nast$new_times), max(sim_SA$new_times))
min_time <- max(min(sim_nast$new_times), min(sim_SA$new_times))

nsamples <- 10000


Y <- sim_nast$count_ensemble[which(sim_nast$new_times<max_time &
                                      sim_nast$new_times>min_time),]
x1 <- sim_SA$count_ensemble[which(sim_SA$new_times<max_time &
                                      sim_SA$new_times>min_time),]

n <- dim(Y)[1]
x0 <- rep(1, n)

# compile covariate with intercept and all x1 generations
X <- matrix(nrow = n, ncol = nsamples*2)
x1.c <- 1
for(i in 1:20000){
  if(i %% 2 != 0) {
    X[,i] <- x0
  } else {
    X[,i] <- x1[,x1.c]
    x1.c <- x1.c + 1
  }
}

```

```{r}
set.seed(3333)
startvals <- c(0,0)
startscales <- c(0.1, 0.002)


startvals <- c(0,0,rep(.1, nrow(Y)))
startscales <- c(0.1, 0.0002, rep(0.5, nrow(Y)))

mcmc_samples_adapt <- chronup::regress(Y = Y,
                            X = X,
                            model = "nb",
                            startvals = startvals,
                            scales = startscales,
                            adapt = T)

burnin <- floor(dim(mcmc_samples_adapt$samples)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$samples)[1], 1)
new_startvals <- colMeans(mcmc_samples_adapt$samples[indeces,])

burnin <- floor(dim(mcmc_samples_adapt$scales)[1] * 0.1)
indeces <- seq(burnin, dim(mcmc_samples_adapt$scales)[1], 1)
new_startscales <- colMeans(mcmc_samples_adapt$scales[indeces,])

mcmc_samples <- chronup::regress(Y = Y,
                        X = X,
                        model = "pois",
                        startvals = new_startvals,
                        scales = new_startscales,
                        adapt = F)

head(mcmc_samples)

plot(mcmc_samples[, 2], type = "l")

quant.1 <- quantile(mcmc_samples[,2], probs = c(0.075, 0.5, 0.925))
plot(density(mcmc_samples[, 2]),
     xlab = "Posterior Estimate")
abline(v = quant.1[1], col = "red")
abline(v = quant.1[3], col = "red")
abline(v = quant.1[2], col = "blue")

# Test probability that it lies above 0
as.data.frame(mcmc_samples[,2]) |>
  dplyr::summarize(prob_greater_0 = mean(mcmc_samples[,2] > 0))
```
